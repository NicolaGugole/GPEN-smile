{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "from face_model.gpen_model_classic import FullGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import utils, transforms\n",
    "topil = transforms.ToPILImage()\n",
    "model_state_reminifaceapp = torch.load('/home/wizard/buckets/bsp-ai-science-scratch/nicg/checkpoints/lifting-gpen/faceapp-remini/classic_gpen/029000.pth')\n",
    "# model_state_reministylegan = torch.load('/home/wizard/buckets/bsp-ai-science-scratch/nicg/checkpoints/lifting-gpen/stylegan-remini/condition_concat_encoder/028000.pth')\n",
    "model_state_reministylegan = torch.load('/home/wizard/buckets/bsp-ai-science-scratch/nicg/checkpoints/lifting-gpen/faceapp-remini/classic_gpen/040000.pth')\n",
    "modelfaceapp = FullGenerator(1024, 512, 8).cuda()\n",
    "modelfaceapp.load_state_dict(model_state_reminifaceapp['g_ema'])\n",
    "modelstylegan = FullGenerator(1024, 512, 8).cuda()\n",
    "modelstylegan.load_state_dict(model_state_reministylegan['g_ema'])\n",
    "\n",
    "SAVE_TEMP_PATH = '/home/wizard/GPEN-smile/temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pydantic in /home/wizard/miniconda/envs/bsp_bendai/lib/python3.9/site-packages (1.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/wizard/miniconda/envs/bsp_bendai/lib/python3.9/site-packages (from pydantic) (4.3.0)\n",
      "\u001b[33mWARNING: Error parsing requirements for bsp-bendai: Parse error at \"'extra =='\": Expected string_end\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torchtyping in /home/wizard/miniconda/envs/bsp_bendai/lib/python3.9/site-packages (0.1.4)\n",
      "Requirement already satisfied: typeguard>=2.11.1 in /home/wizard/miniconda/envs/bsp_bendai/lib/python3.9/site-packages (from torchtyping) (2.13.3)\n",
      "Requirement already satisfied: torch>=1.7.0 in /home/wizard/miniconda/envs/bsp_bendai/lib/python3.9/site-packages (from torchtyping) (1.11.0)\n",
      "Requirement already satisfied: typing_extensions in /home/wizard/miniconda/envs/bsp_bendai/lib/python3.9/site-packages (from torch>=1.7.0->torchtyping) (4.3.0)\n",
      "\u001b[33mWARNING: Error parsing requirements for bsp-bendai: Parse error at \"'extra =='\": Expected string_end\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pydantic\n",
    "!pip install torchtyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bsp_logging'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, DIFFAE_DIR)\n\u001b[1;32m      6\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(DIFFAE_DIR)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mproduction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mremini\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReminiEnhanceHandler, Request\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mproduction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mremini\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup_model\n\u001b[1;32m      9\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, THIS_DIR)\n",
      "File \u001b[0;32m~/bendai-lib-python/production/remini/app/handler.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbsp_bendai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mface_enhancement\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mremini\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mface_blender\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FaceBlender\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbsp_bendai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mface_enhancement\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mremini\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_side, compute_true_side\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mproduction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mremini\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     ENHANCE_CONFIGS,\n\u001b[1;32m     23\u001b[0m     PIPELINE_CONFIGS,\n\u001b[1;32m     24\u001b[0m     EnhanceConfig,\n\u001b[1;32m     25\u001b[0m     PipelineConfig,\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mproduction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mremini\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_manipulator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageManipulator\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mproduction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mremini\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReminiEnhanceMetrics\n",
      "File \u001b[0;32m~/bendai-lib-python/production/remini/app/config.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mproduction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon_logs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogLevel\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mproduction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     12\u001b[0m     CheckpointPath,\n\u001b[1;32m     13\u001b[0m     ProdBaseConfig,\n\u001b[1;32m     14\u001b[0m     RelativeCheckpointPathValidator,\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# The cuda functions works only with GPU so when there is only cpu we use a torch implementation\u001b[39;00m\n",
      "File \u001b[0;32m~/bendai-lib-python/production/utilities/common_logs.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menum\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional, cast\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbsp_logging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilters\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mthread_prop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ThreadPropLogFilter\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbsp_logging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstructured\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup_compute_engine\n\u001b[1;32m      8\u001b[0m BSP_TRACE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrace\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bsp_logging'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "THIS_DIR = os.getcwd()\n",
    "DIFFAE_DIR = '/home/wizard/bendai-lib-python/'\n",
    "sys.path.insert(0, DIFFAE_DIR)\n",
    "os.chdir(DIFFAE_DIR)\n",
    "from production.remini.app.handler import ReminiEnhanceHandler, Request\n",
    "from production.remini.app.main import setup_model\n",
    "sys.path.insert(0, THIS_DIR)\n",
    "os.chdir(THIS_DIR)\n",
    "def make_model() -> ReminiEnhanceHandler:\n",
    "    print(\"\\nLoading model... \")\n",
    "    handler = setup_model()\n",
    "    print(\"Model loaded!\\n\\n\")\n",
    "    return handler\n",
    "def process_img(model, img_path):\n",
    "    request = Request(\n",
    "        \n",
    "            input_path=img_path,\n",
    "            output_path='/home/wizard/GPEN-smile/temp/temp_remini',\n",
    "            enhance_config=\"enhance-a\",\n",
    "            output_format=\"image/jpeg\",\n",
    "            pipeline_config=\"production\",\n",
    "            edit_mode='latent_mapper',\n",
    "            edit_strength=1.0,\n",
    "            edit_choice='Attractive',\n",
    "            edit_enabled=False,\n",
    "        )\n",
    "    responsefaceapp = modelfaceapp.inference(request)\n",
    "    responsestylegan = modelstylegan.inference(request)\n",
    "    return Image.open(responsefaceapp.enhanced_image_path), Image.open(responsestylegan.enhanced_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "dir = '/home/wizard/GPEN-smile/examples/remini-small'\n",
    "imgs = []\n",
    "remini_model = make_model()\n",
    "for img_path in [os.path.join(dir, i) for i in os.listdir(dir)][5:]:\n",
    "    input = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    input_orig = cv2.cvtColor(input, cv2.COLOR_BGR2RGB)\n",
    "    input = torch.from_numpy(input).cuda().permute(2, 0, 1).unsqueeze(0)\n",
    "    img_t = (input/255.-0.5)/0.5\n",
    "    img_t = F.interpolate(img_t, (1024, 1024))\n",
    "    img_t = torch.flip(img_t, [1])\n",
    "    output, _ = model(img_t, 15000)\n",
    "    grid = utils.make_grid(\n",
    "                                    output,\n",
    "                                    nrow=1,\n",
    "                                    normalize=True,\n",
    "                                    range=(-1, 1),\n",
    "                                )\n",
    "    topil(grid.cpu()).save(os.path.join(SAVE_TEMP_PATH, img_path.split('/')[-1]))\n",
    "    remini_output = process_img(remini_model, os.path.join(SAVE_TEMP_PATH, img_path.split('/')[-1]))\n",
    "    fig, axs = plt.subplots(1, 3, figsize = (30,10))\n",
    "    axs[0].imshow(input_orig)\n",
    "    axs[1].imshow(topil(grid.cpu()))\n",
    "    axs[2].imshow(remini_output)\n",
    "    plt.show()\n",
    "    del input, img_t, grid, remini_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/home/wizard/GPEN-smile/examples/orig.png'\n",
    "input = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "input_orig = cv2.cvtColor(input, cv2.COLOR_BGR2RGB)\n",
    "input = torch.from_numpy(input).cuda().permute(2, 0, 1).unsqueeze(0)\n",
    "img_t = (input/255.-0.5)/0.5\n",
    "img_t = F.interpolate(img_t, (1024, 1024))\n",
    "img_t = torch.flip(img_t, [1])\n",
    "output, _ = model(img_t, 15000)\n",
    "grid = utils.make_grid(\n",
    "                                output,\n",
    "                                nrow=1,\n",
    "                                normalize=True,\n",
    "                                range=(-1, 1),\n",
    "                            )\n",
    "topil(grid.cpu()).save(os.path.join(SAVE_TEMP_PATH, img_path.split('/')[-1]))\n",
    "remini_output = process_img(remini_model, os.path.join(SAVE_TEMP_PATH, img_path.split('/')[-1]))\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize = (30,10)) \n",
    "axs[0].imshow(input_orig)\n",
    "axs[1].imshow(topil(grid.cpu()))\n",
    "axs[2].imshow(remini_output)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/home/wizard/diffae/imgs_align/davide_coca.png'\n",
    "input = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "input_orig = cv2.cvtColor(input, cv2.COLOR_BGR2RGB)\n",
    "input = torch.from_numpy(input).cuda().permute(2, 0, 1).unsqueeze(0)\n",
    "img_t = (input/255.-0.5)/0.5\n",
    "img_t = F.interpolate(img_t, (1024, 1024))\n",
    "img_t = torch.flip(img_t, [1])\n",
    "output, _ = model(img_t, 15000)\n",
    "grid = utils.make_grid(\n",
    "                                output,\n",
    "                                nrow=1,\n",
    "                                normalize=True,\n",
    "                                range=(-1, 1),\n",
    "                            )\n",
    "topil(grid.cpu()).save(os.path.join(SAVE_TEMP_PATH, img_path.split('/')[-1]))\n",
    "remini_output = process_img(remini_model, os.path.join(SAVE_TEMP_PATH, img_path.split('/')[-1]))\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize = (30,10)) \n",
    "axs[0].imshow(input_orig)\n",
    "axs[1].imshow(topil(grid.cpu()))\n",
    "axs[2].imshow(remini_output)\n",
    "plt.show()\n",
    "topil(torch.Tensor(input_orig)[0]).save('orig.jpg')\n",
    "remini_output.save('edited.jpg')\n",
    "topil(grid.cpu()).save('editednonremini.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d74a2f9f7c527db08cd3d49269c633cb9a17657d122894231558546750c378fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
